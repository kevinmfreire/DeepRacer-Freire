{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed DeepRacer RL training with SageMaker and RoboMaker\n",
    "\n",
    "---\n",
    "## Introduction\n",
    "\n",
    "\n",
    "In this notebook, we will train a fully autonomous 1/18th scale race car using reinforcement learning using Amazon SageMaker RL and AWS RoboMaker's 3D driving simulator. [AWS RoboMaker](https://console.aws.amazon.com/robomaker/home#welcome) is a service that makes it easy for developers to develop, test, and deploy robotics applications.  \n",
    "\n",
    "This notebook provides a jailbreak experience of [AWS DeepRacer](https://console.aws.amazon.com/deepracer/home#welcome), giving us more control over the training/simulation process and RL algorithm tuning.\n",
    "\n",
    "![Training in Action](./deepracer-reinvent-track.jpg)\n",
    "\n",
    "\n",
    "---\n",
    "## How it works?  \n",
    "\n",
    "![How training works](./training.png)\n",
    "\n",
    "The reinforcement learning agent (i.e. our autonomous car) learns to drive by interacting with its environment, e.g., the track, by taking an action in a given state to maximize the expected reward. The agent learns the optimal plan of actions in training by trial-and-error through repeated episodes.  \n",
    "  \n",
    "The figure above shows an example of distributed RL training across SageMaker and two RoboMaker simulation envrionments that perform the **rollouts** - execute a fixed number of episodes using the current model or policy. The rollouts collect agent experiences (state-transition tuples) and share this data with SageMaker for training. SageMaker updates the model policy which is then used to execute the next sequence of rollouts. This training loop continues until the model converges, i.e. the car learns to drive and stops going off-track. More formally, we can define the problem in terms of the following:  \n",
    "\n",
    "1. **Objective**: Learn to drive autonomously by staying close to the center of the track.\n",
    "2. **Environment**: A 3D driving simulator hosted on AWS RoboMaker.\n",
    "3. **State**: The driving POV image captured by the car's head camera, as shown in the illustration above.\n",
    "4. **Action**: Six discrete steering wheel positions at different angles (configurable)\n",
    "5. **Reward**: Positive reward for staying close to the center line; High penalty for going off-track. This is configurable and can be made more complex (for e.g. steering penalty can be added)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run these command if you wish to modify the SageMaker and Robomaker code\n",
    "<span style=\"color:red\">Note: Make sure you have atleast 25 GB of space when you are planning to modify the Sagemaker and Robomaker code</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all files in ./build\n",
      "download: s3://deepracer-managed-resources-us-east-1/deepracer-simapp.tar.gz to ./deepracer-simapp.tar.gz\n",
      "Untarring all files in ./build/simapp/\n",
      "tar -xvf ./deepracer-simapp.tar.gz -C build/simapp/\n",
      "tar -xvf build/simapp/bundle.tar -C build/simapp/bundle\n",
      "tar -xvf build/simapp/metadata.tar -C build/simapp/\n",
      "sending incremental file list\n",
      "./\n",
      "__init__.py\n",
      "camera_utils.py\n",
      "common.py\n",
      "constants.py\n",
      "deepracer_memory.py\n",
      "defaults.py\n",
      "evaluation_worker.py\n",
      "rollout_constants.py\n",
      "rollout_utils.py\n",
      "rollout_worker.py\n",
      "rospy_wrappers.py\n",
      "s3_boto_data_store.py\n",
      "sagemaker_graph_manager.py\n",
      "training_worker.py\n",
      "utils.py\n",
      "validation_worker.py\n",
      "virtual_event_worker.py\n",
      "__pycache__/\n",
      "__pycache__/__init__.cpython-35.pyc\n",
      "__pycache__/camera_utils.cpython-35.pyc\n",
      "__pycache__/common.cpython-35.pyc\n",
      "__pycache__/constants.cpython-35.pyc\n",
      "__pycache__/deepracer_memory.cpython-35.pyc\n",
      "__pycache__/defaults.cpython-35.pyc\n",
      "__pycache__/evaluation_worker.cpython-35.pyc\n",
      "__pycache__/rollout_constants.cpython-35.pyc\n",
      "__pycache__/rollout_utils.cpython-35.pyc\n",
      "__pycache__/rollout_worker.cpython-35.pyc\n",
      "__pycache__/rospy_wrappers.cpython-35.pyc\n",
      "__pycache__/s3_boto_data_store.cpython-35.pyc\n",
      "__pycache__/sagemaker_graph_manager.cpython-35.pyc\n",
      "__pycache__/training_worker.cpython-35.pyc\n",
      "__pycache__/utils.cpython-35.pyc\n",
      "__pycache__/validation_worker.cpython-35.pyc\n",
      "__pycache__/virtual_event_worker.cpython-35.pyc\n",
      "agent_ctrl/\n",
      "agent_ctrl/__init__.py\n",
      "agent_ctrl/agent_ctrl_interface.py\n",
      "agent_ctrl/bot_cars_agent_ctrl.py\n",
      "agent_ctrl/constants.py\n",
      "agent_ctrl/obstacles_agent_ctrl.py\n",
      "agent_ctrl/rollout_agent_ctrl.py\n",
      "agent_ctrl/training_agent_ctrl.py\n",
      "agent_ctrl/utils.py\n",
      "agent_ctrl/__pycache__/\n",
      "agent_ctrl/__pycache__/__init__.cpython-35.pyc\n",
      "agent_ctrl/__pycache__/agent_ctrl_interface.cpython-35.pyc\n",
      "agent_ctrl/__pycache__/bot_cars_agent_ctrl.cpython-35.pyc\n",
      "agent_ctrl/__pycache__/constants.cpython-35.pyc\n",
      "agent_ctrl/__pycache__/obstacles_agent_ctrl.cpython-35.pyc\n",
      "agent_ctrl/__pycache__/rollout_agent_ctrl.cpython-35.pyc\n",
      "agent_ctrl/__pycache__/training_agent_ctrl.cpython-35.pyc\n",
      "agent_ctrl/__pycache__/utils.cpython-35.pyc\n",
      "agents/\n",
      "agents/__init__.py\n",
      "agents/agent.py\n",
      "agents/rollout_agent_factory.py\n",
      "agents/training_agent_factory.py\n",
      "agents/utils.py\n",
      "agents/__pycache__/\n",
      "agents/__pycache__/__init__.cpython-35.pyc\n",
      "agents/__pycache__/agent.cpython-35.pyc\n",
      "agents/__pycache__/rollout_agent_factory.cpython-35.pyc\n",
      "agents/__pycache__/training_agent_factory.cpython-35.pyc\n",
      "agents/__pycache__/utils.cpython-35.pyc\n",
      "architecture/\n",
      "architecture/__init__.py\n",
      "architecture/constants.py\n",
      "architecture/contrib.py\n",
      "architecture/custom_architectures.py\n",
      "architecture/embedder_factory.py\n",
      "architecture/__pycache__/\n",
      "architecture/__pycache__/__init__.cpython-35.pyc\n",
      "architecture/__pycache__/constants.cpython-35.pyc\n",
      "architecture/__pycache__/contrib.cpython-35.pyc\n",
      "architecture/__pycache__/custom_architectures.cpython-35.pyc\n",
      "architecture/__pycache__/embedder_factory.cpython-35.pyc\n",
      "auth/\n",
      "auth/__init__.py\n",
      "auth/refreshed_session.py\n",
      "auth/__pycache__/\n",
      "auth/__pycache__/__init__.cpython-35.pyc\n",
      "auth/__pycache__/refreshed_session.cpython-35.pyc\n",
      "boto/\n",
      "boto/__init__.py\n",
      "boto/constants.py\n",
      "boto/deepracer_boto_client.py\n",
      "boto/__pycache__/\n",
      "boto/__pycache__/__init__.cpython-35.pyc\n",
      "boto/__pycache__/constants.cpython-35.pyc\n",
      "boto/__pycache__/deepracer_boto_client.cpython-35.pyc\n",
      "boto/s3/\n",
      "boto/s3/__init__.py\n",
      "boto/s3/constants.py\n",
      "boto/s3/s3_client.py\n",
      "boto/s3/utils.py\n",
      "boto/s3/__pycache__/\n",
      "boto/s3/__pycache__/__init__.cpython-35.pyc\n",
      "boto/s3/__pycache__/constants.cpython-35.pyc\n",
      "boto/s3/__pycache__/s3_client.cpython-35.pyc\n",
      "boto/s3/__pycache__/utils.cpython-35.pyc\n",
      "boto/s3/files/\n",
      "boto/s3/files/__init__.py\n",
      "boto/s3/files/checkpoint.py\n",
      "boto/s3/files/hyperparameters.py\n",
      "boto/s3/files/ip_config.py\n",
      "boto/s3/files/metrics.py\n",
      "boto/s3/files/model_metadata.py\n",
      "boto/s3/files/reward_function.py\n",
      "boto/s3/files/simtrace_video.py\n",
      "boto/s3/files/virtual_event_best_sector_time.py\n",
      "boto/s3/files/yaml_file.py\n",
      "boto/s3/files/__pycache__/\n",
      "boto/s3/files/__pycache__/__init__.cpython-35.pyc\n",
      "boto/s3/files/__pycache__/checkpoint.cpython-35.pyc\n",
      "boto/s3/files/__pycache__/hyperparameters.cpython-35.pyc\n",
      "boto/s3/files/__pycache__/ip_config.cpython-35.pyc\n",
      "boto/s3/files/__pycache__/metrics.cpython-35.pyc\n",
      "boto/s3/files/__pycache__/model_metadata.cpython-35.pyc\n",
      "boto/s3/files/__pycache__/reward_function.cpython-35.pyc\n",
      "boto/s3/files/__pycache__/simtrace_video.cpython-35.pyc\n",
      "boto/s3/files/__pycache__/virtual_event_best_sector_time.cpython-35.pyc\n",
      "boto/s3/files/__pycache__/yaml_file.cpython-35.pyc\n",
      "boto/s3/files/checkpoint_files/\n",
      "boto/s3/files/checkpoint_files/__init__.py\n",
      "boto/s3/files/checkpoint_files/deepracer_checkpoint_json.py\n",
      "boto/s3/files/checkpoint_files/rl_coach_checkpoint.py\n",
      "boto/s3/files/checkpoint_files/rl_coach_sync_file.py\n",
      "boto/s3/files/checkpoint_files/tensorflow_model.py\n",
      "boto/s3/files/checkpoint_files/__pycache__/\n",
      "boto/s3/files/checkpoint_files/__pycache__/__init__.cpython-35.pyc\n",
      "boto/s3/files/checkpoint_files/__pycache__/deepracer_checkpoint_json.cpython-35.pyc\n",
      "boto/s3/files/checkpoint_files/__pycache__/rl_coach_checkpoint.cpython-35.pyc\n",
      "boto/s3/files/checkpoint_files/__pycache__/rl_coach_sync_file.cpython-35.pyc\n",
      "boto/s3/files/checkpoint_files/__pycache__/tensorflow_model.cpython-35.pyc\n",
      "boto/sqs/\n",
      "boto/sqs/__init__.py\n",
      "boto/sqs/constants.py\n",
      "boto/sqs/sqs_client.py\n",
      "boto/sqs/__pycache__/\n",
      "boto/sqs/__pycache__/__init__.cpython-35.pyc\n",
      "boto/sqs/__pycache__/constants.cpython-35.pyc\n",
      "boto/sqs/__pycache__/sqs_client.cpython-35.pyc\n",
      "cameras/\n",
      "cameras/__init__.py\n",
      "cameras/abs_camera.py\n",
      "cameras/camera_factory.py\n",
      "cameras/camera_manager.py\n",
      "cameras/constants.py\n",
      "cameras/frustum.py\n",
      "cameras/frustum_manager.py\n",
      "cameras/utils.py\n",
      "cameras/__pycache__/\n",
      "cameras/__pycache__/__init__.cpython-35.pyc\n",
      "cameras/__pycache__/abs_camera.cpython-35.pyc\n",
      "cameras/__pycache__/camera_factory.cpython-35.pyc\n",
      "cameras/__pycache__/camera_manager.cpython-35.pyc\n",
      "cameras/__pycache__/constants.cpython-35.pyc\n",
      "cameras/__pycache__/frustum.cpython-35.pyc\n",
      "cameras/__pycache__/frustum_manager.cpython-35.pyc\n",
      "cameras/__pycache__/utils.cpython-35.pyc\n",
      "cameras/handlers/\n",
      "cameras/handlers/__init__.py\n",
      "cameras/handlers/follow_car_camera.py\n",
      "cameras/handlers/top_camera.py\n",
      "cameras/handlers/__pycache__/\n",
      "cameras/handlers/__pycache__/__init__.cpython-35.pyc\n",
      "cameras/handlers/__pycache__/follow_car_camera.cpython-35.pyc\n",
      "cameras/handlers/__pycache__/top_camera.cpython-35.pyc\n",
      "domain_randomizations/\n",
      "domain_randomizations/__init__.py\n",
      "domain_randomizations/abs_randomizer.py\n",
      "domain_randomizations/constants.py\n",
      "domain_randomizations/randomizer_manager.py\n",
      "domain_randomizations/__pycache__/\n",
      "domain_randomizations/__pycache__/__init__.cpython-35.pyc\n",
      "domain_randomizations/__pycache__/abs_randomizer.cpython-35.pyc\n",
      "domain_randomizations/__pycache__/constants.cpython-35.pyc\n",
      "domain_randomizations/__pycache__/randomizer_manager.cpython-35.pyc\n",
      "domain_randomizations/visual/\n",
      "domain_randomizations/visual/__init__.py\n",
      "domain_randomizations/visual/light_randomizer.py\n",
      "domain_randomizations/visual/model_visual_randomizer.py\n",
      "domain_randomizations/visual/__pycache__/\n",
      "domain_randomizations/visual/__pycache__/__init__.cpython-35.pyc\n",
      "domain_randomizations/visual/__pycache__/light_randomizer.cpython-35.pyc\n",
      "domain_randomizations/visual/__pycache__/model_visual_randomizer.cpython-35.pyc\n",
      "environments/\n",
      "environments/__init__.py\n",
      "environments/constants.py\n",
      "environments/deepracer_racetrack_env.py\n",
      "environments/__pycache__/\n",
      "environments/__pycache__/__init__.cpython-35.pyc\n",
      "environments/__pycache__/constants.cpython-35.pyc\n",
      "environments/__pycache__/deepracer_racetrack_env.cpython-35.pyc\n",
      "exploration_policies/\n",
      "exploration_policies/__init__.py\n",
      "exploration_policies/deepracer_categorical.py\n",
      "exploration_policies/__pycache__/\n",
      "exploration_policies/__pycache__/__init__.cpython-35.pyc\n",
      "exploration_policies/__pycache__/deepracer_categorical.cpython-35.pyc\n",
      "filters/\n",
      "filters/__init__.py\n",
      "filters/__pycache__/\n",
      "filters/__pycache__/__init__.cpython-35.pyc\n",
      "filters/observation/\n",
      "filters/observation/__init__.py\n",
      "filters/observation/observation_binary_filter.py\n",
      "filters/observation/__pycache__/\n",
      "filters/observation/__pycache__/__init__.cpython-35.pyc\n",
      "filters/observation/__pycache__/observation_binary_filter.cpython-35.pyc\n",
      "gazebo_tracker/\n",
      "gazebo_tracker/__init__.py\n",
      "gazebo_tracker/abs_tracker.py\n",
      "gazebo_tracker/constants.py\n",
      "gazebo_tracker/tracker_manager.py\n",
      "gazebo_tracker/__pycache__/\n",
      "gazebo_tracker/__pycache__/__init__.cpython-35.pyc\n",
      "gazebo_tracker/__pycache__/abs_tracker.cpython-35.pyc\n",
      "gazebo_tracker/__pycache__/constants.cpython-35.pyc\n",
      "gazebo_tracker/__pycache__/tracker_manager.cpython-35.pyc\n",
      "gazebo_tracker/trackers/\n",
      "gazebo_tracker/trackers/__init__.py\n",
      "gazebo_tracker/trackers/get_link_state_tracker.py\n",
      "gazebo_tracker/trackers/get_model_state_tracker.py\n",
      "gazebo_tracker/trackers/set_model_state_tracker.py\n",
      "gazebo_tracker/trackers/set_visual_color_tracker.py\n",
      "gazebo_tracker/trackers/set_visual_transparency_tracker.py\n",
      "gazebo_tracker/trackers/__pycache__/\n",
      "gazebo_tracker/trackers/__pycache__/__init__.cpython-35.pyc\n",
      "gazebo_tracker/trackers/__pycache__/get_link_state_tracker.cpython-35.pyc\n",
      "gazebo_tracker/trackers/__pycache__/get_model_state_tracker.cpython-35.pyc\n",
      "gazebo_tracker/trackers/__pycache__/set_model_state_tracker.cpython-35.pyc\n",
      "gazebo_tracker/trackers/__pycache__/set_visual_color_tracker.cpython-35.pyc\n",
      "gazebo_tracker/trackers/__pycache__/set_visual_transparency_tracker.cpython-35.pyc\n",
      "gazebo_utils/\n",
      "gazebo_utils/__init__.py\n",
      "gazebo_utils/model_updater.py\n",
      "gazebo_utils/__pycache__/\n",
      "gazebo_utils/__pycache__/__init__.cpython-35.pyc\n",
      "gazebo_utils/__pycache__/model_updater.cpython-35.pyc\n",
      "log_handler/\n",
      "log_handler/__init__.py\n",
      "log_handler/constants.py\n",
      "log_handler/deepracer_exceptions.py\n",
      "log_handler/exception_handler.py\n",
      "log_handler/logger.py\n",
      "log_handler/__pycache__/\n",
      "log_handler/__pycache__/__init__.cpython-35.pyc\n",
      "log_handler/__pycache__/constants.cpython-35.pyc\n",
      "log_handler/__pycache__/deepracer_exceptions.cpython-35.pyc\n",
      "log_handler/__pycache__/exception_handler.cpython-35.pyc\n",
      "log_handler/__pycache__/logger.cpython-35.pyc\n",
      "memories/\n",
      "memories/__init__.py\n",
      "memories/deepracer_memory.py\n",
      "memories/__pycache__/\n",
      "memories/__pycache__/__init__.cpython-35.pyc\n",
      "memories/__pycache__/deepracer_memory.cpython-35.pyc\n",
      "metrics/\n",
      "metrics/__init__.py\n",
      "metrics/constants.py\n",
      "metrics/iteration_data.py\n",
      "metrics/metrics_interface.py\n",
      "metrics/s3_metrics.py\n",
      "metrics/__pycache__/\n",
      "metrics/__pycache__/__init__.cpython-35.pyc\n",
      "metrics/__pycache__/constants.cpython-35.pyc\n",
      "metrics/__pycache__/iteration_data.cpython-35.pyc\n",
      "metrics/__pycache__/metrics_interface.cpython-35.pyc\n",
      "metrics/__pycache__/s3_metrics.cpython-35.pyc\n",
      "multi_agent_coach/\n",
      "multi_agent_coach/__init__.py\n",
      "multi_agent_coach/action_space_configs.py\n",
      "multi_agent_coach/multi_agent_environment.py\n",
      "multi_agent_coach/multi_agent_graph_manager.py\n",
      "multi_agent_coach/multi_agent_level_manager.py\n",
      "multi_agent_coach/spaces.py\n",
      "multi_agent_coach/__pycache__/\n",
      "multi_agent_coach/__pycache__/__init__.cpython-35.pyc\n",
      "multi_agent_coach/__pycache__/action_space_configs.cpython-35.pyc\n",
      "multi_agent_coach/__pycache__/multi_agent_environment.cpython-35.pyc\n",
      "multi_agent_coach/__pycache__/multi_agent_graph_manager.cpython-35.pyc\n",
      "multi_agent_coach/__pycache__/multi_agent_level_manager.cpython-35.pyc\n",
      "multi_agent_coach/__pycache__/spaces.cpython-35.pyc\n",
      "multi_agent_coach/agents/\n",
      "multi_agent_coach/agents/__init__.py\n",
      "multi_agent_coach/agents/sac_agent.py\n",
      "multi_agent_coach/agents/__pycache__/\n",
      "multi_agent_coach/agents/__pycache__/__init__.cpython-35.pyc\n",
      "multi_agent_coach/agents/__pycache__/sac_agent.cpython-35.pyc\n",
      "multi_agent_coach/architectures/\n",
      "multi_agent_coach/architectures/__init__.py\n",
      "multi_agent_coach/architectures/head_parameters.py\n",
      "multi_agent_coach/architectures/__pycache__/\n",
      "multi_agent_coach/architectures/__pycache__/__init__.cpython-35.pyc\n",
      "multi_agent_coach/architectures/__pycache__/head_parameters.cpython-35.pyc\n",
      "multi_agent_coach/architectures/tensorflow_components/\n",
      "multi_agent_coach/architectures/tensorflow_components/__init__.py\n",
      "multi_agent_coach/architectures/tensorflow_components/__pycache__/\n",
      "multi_agent_coach/architectures/tensorflow_components/__pycache__/__init__.cpython-35.pyc\n",
      "multi_agent_coach/architectures/tensorflow_components/heads/\n",
      "multi_agent_coach/architectures/tensorflow_components/heads/__init__.py\n",
      "multi_agent_coach/architectures/tensorflow_components/heads/sac_head.py\n",
      "multi_agent_coach/architectures/tensorflow_components/heads/sac_q_head.py\n",
      "multi_agent_coach/architectures/tensorflow_components/heads/__pycache__/\n",
      "multi_agent_coach/architectures/tensorflow_components/heads/__pycache__/__init__.cpython-35.pyc\n",
      "multi_agent_coach/architectures/tensorflow_components/heads/__pycache__/sac_head.cpython-35.pyc\n",
      "multi_agent_coach/architectures/tensorflow_components/heads/__pycache__/sac_q_head.cpython-35.pyc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset/\n",
      "reset/__init__.py\n",
      "reset/abstract_reset_rule.py\n",
      "reset/constants.py\n",
      "reset/reset_rules_manager.py\n",
      "reset/utils.py\n",
      "reset/__pycache__/\n",
      "reset/__pycache__/__init__.cpython-35.pyc\n",
      "reset/__pycache__/abstract_reset_rule.cpython-35.pyc\n",
      "reset/__pycache__/constants.cpython-35.pyc\n",
      "reset/__pycache__/reset_rules_manager.cpython-35.pyc\n",
      "reset/__pycache__/utils.cpython-35.pyc\n",
      "reset/rules/\n",
      "reset/rules/__init__.py\n",
      "reset/rules/crash_reset_rule.py\n",
      "reset/rules/episode_complete_reset_rule.py\n",
      "reset/rules/immobilized_reset_rule.py\n",
      "reset/rules/off_track_reset_rule.py\n",
      "reset/rules/race_time_rule.py\n",
      "reset/rules/reverse_reset_rule.py\n",
      "reset/rules/__pycache__/\n",
      "reset/rules/__pycache__/__init__.cpython-35.pyc\n",
      "reset/rules/__pycache__/crash_reset_rule.cpython-35.pyc\n",
      "reset/rules/__pycache__/episode_complete_reset_rule.cpython-35.pyc\n",
      "reset/rules/__pycache__/immobilized_reset_rule.cpython-35.pyc\n",
      "reset/rules/__pycache__/off_track_reset_rule.cpython-35.pyc\n",
      "reset/rules/__pycache__/race_time_rule.cpython-35.pyc\n",
      "reset/rules/__pycache__/reverse_reset_rule.cpython-35.pyc\n",
      "samples/\n",
      "samples/__init__.py\n",
      "samples/sample_collector.py\n",
      "samples/__pycache__/\n",
      "samples/__pycache__/__init__.cpython-35.pyc\n",
      "samples/__pycache__/sample_collector.cpython-35.pyc\n",
      "sensors/\n",
      "sensors/__init__.py\n",
      "sensors/composite_sensor.py\n",
      "sensors/sensor_interface.py\n",
      "sensors/sensors_rollout.py\n",
      "sensors/sensors_training.py\n",
      "sensors/utils.py\n",
      "sensors/__pycache__/\n",
      "sensors/__pycache__/__init__.cpython-35.pyc\n",
      "sensors/__pycache__/composite_sensor.cpython-35.pyc\n",
      "sensors/__pycache__/sensor_interface.cpython-35.pyc\n",
      "sensors/__pycache__/sensors_rollout.cpython-35.pyc\n",
      "sensors/__pycache__/sensors_training.cpython-35.pyc\n",
      "sensors/__pycache__/utils.cpython-35.pyc\n",
      "state_machine/\n",
      "state_machine/__init__.py\n",
      "state_machine/abs_fsm_state.py\n",
      "state_machine/fsm.py\n",
      "state_machine/__pycache__/\n",
      "state_machine/__pycache__/__init__.cpython-35.pyc\n",
      "state_machine/__pycache__/abs_fsm_state.cpython-35.pyc\n",
      "state_machine/__pycache__/fsm.cpython-35.pyc\n",
      "track_geom/\n",
      "track_geom/__init__.py\n",
      "track_geom/constants.py\n",
      "track_geom/track_data.py\n",
      "track_geom/utils.py\n",
      "track_geom/__pycache__/\n",
      "track_geom/__pycache__/__init__.cpython-35.pyc\n",
      "track_geom/__pycache__/constants.cpython-35.pyc\n",
      "track_geom/__pycache__/track_data.cpython-35.pyc\n",
      "track_geom/__pycache__/utils.cpython-35.pyc\n",
      "track_geom/spline/\n",
      "track_geom/spline/__init__.py\n",
      "track_geom/spline/abstract_spline.py\n",
      "track_geom/spline/lane_change_spline.py\n",
      "track_geom/spline/track_spline.py\n",
      "track_geom/spline/__pycache__/\n",
      "track_geom/spline/__pycache__/__init__.cpython-35.pyc\n",
      "track_geom/spline/__pycache__/abstract_spline.cpython-35.pyc\n",
      "track_geom/spline/__pycache__/lane_change_spline.cpython-35.pyc\n",
      "track_geom/spline/__pycache__/track_spline.cpython-35.pyc\n",
      "virtual_event/\n",
      "virtual_event/__init__.py\n",
      "virtual_event/constants.py\n",
      "virtual_event/utils.py\n",
      "virtual_event/virtual_event_manager.py\n",
      "virtual_event/__pycache__/\n",
      "virtual_event/__pycache__/__init__.cpython-35.pyc\n",
      "virtual_event/__pycache__/constants.cpython-35.pyc\n",
      "virtual_event/__pycache__/utils.cpython-35.pyc\n",
      "virtual_event/__pycache__/virtual_event_manager.cpython-35.pyc\n",
      "visual_effects/\n",
      "visual_effects/__init__.py\n",
      "visual_effects/abs_effect.py\n",
      "visual_effects/effect_manager.py\n",
      "visual_effects/__pycache__/\n",
      "visual_effects/__pycache__/__init__.cpython-35.pyc\n",
      "visual_effects/__pycache__/abs_effect.cpython-35.pyc\n",
      "visual_effects/__pycache__/effect_manager.cpython-35.pyc\n",
      "visual_effects/effects/\n",
      "visual_effects/effects/__init__.py\n",
      "visual_effects/effects/blink_effect.py\n",
      "visual_effects/effects/__pycache__/\n",
      "visual_effects/effects/__pycache__/__init__.cpython-35.pyc\n",
      "visual_effects/effects/__pycache__/blink_effect.cpython-35.pyc\n",
      "visualizations/\n",
      "visualizations/__init__.py\n",
      "visualizations/reward_distributions.py\n",
      "visualizations/__pycache__/\n",
      "visualizations/__pycache__/__init__.cpython-35.pyc\n",
      "visualizations/__pycache__/reward_distributions.cpython-35.pyc\n",
      "\n",
      "sent 1713677 bytes  received 6715 bytes  3440784.00 bytes/sec\n",
      "total size is 1686793  speedup is 0.98\n",
      "############################################\n",
      "This command execution takes around >2 min...\n",
      "Bundling the SimApp output.tar.gz\n",
      "Creating tar of build/simapp/bundle\n",
      "Removing the previously created tar files\n",
      "============ Archiving completed. Available at build/Output.tar.gz============ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Run these commands only for the first time\n",
    "#\n",
    "# Clean the build directory if present\n",
    "!python3 sim_app_bundler.py --clean\n",
    "\n",
    "# Download Robomaker simApp from the deepracer public s3 bucket\n",
    "simulation_application_bundle_location = \"s3://deepracer-managed-resources-us-east-1/deepracer-simapp.tar.gz\"\n",
    "!aws s3 cp {simulation_application_bundle_location} ./\n",
    "\n",
    "# Untar the simapp bundle\n",
    "!python3 sim_app_bundler.py --untar ./deepracer-simapp.tar.gz\n",
    "\n",
    "# Now modify the simapp(Robomaker) from build directory and run this command.\n",
    "\n",
    "# Most of the simapp files can be found here (Robomaker changes). You can modify them in these locations\n",
    "# bundle/opt/install/sagemaker_rl_agent/lib/python3.5/site-packages/\n",
    "# bundle/opt/install/deepracer_simulation_environment/share/deepracer_simulation_environment/\n",
    "# bundle/opt/install/deepracer_simulation_environment/lib/deepracer_simulation_environment/\n",
    "\n",
    "# # Copying the notebook src/markov changes to the simapp (For sagemaker container)\n",
    "!rsync -av ./src/markov/ ./build/simapp/bundle/opt/install/sagemaker_rl_agent/lib/python3.5/site-packages/markov\n",
    "\n",
    "print(\"############################################\")\n",
    "print(\"This command execution takes around >2 min...\")\n",
    "!python3 sim_app_bundler.py --tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get latest markov package from the bundle to run on SageMaker instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# # Run these commands only for the first time\n",
    "# #\n",
    "# # Clean the build directory if present\n",
    "# !python3 sim_app_bundler.py --clean\n",
    "\n",
    "# # Download Robomaker simApp from the deepracer public s3 bucket\n",
    "# simulation_application_bundle_location = \"s3://deepracer-managed-resources-us-east-1/deepracer-simapp.tar.gz\"\n",
    "# !aws s3 cp {simulation_application_bundle_location} ./deepracer-simapp.tar.gz\n",
    "\n",
    "# # Untar the simapp bundle\n",
    "# !python3 sim_app_bundler.py --untar ./deepracer-simapp.tar.gz\n",
    "\n",
    "# !rm -rf ./src/markov\n",
    "# !cp -r build/simapp/bundle/opt/install/sagemaker_rl_agent/lib/python3.5/site-packages/markov ./src/\n",
    "\n",
    "# # Remove build & deepracer-simapp.tar.gz\n",
    "# !rm -rf build\n",
    "# !rm -rf deepracer-simapp.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we'll import the Python libraries we need, set up the environment with a few prerequisites for permissions and configurations.\n",
    "\n",
    "You can run this notebook from your local machine or from a SageMaker notebook instance. In both of these scenarios, you can run the following to launch a training job on SageMaker and a simulation job on RoboMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import yaml\n",
    "sys.path.append(\"common\")\n",
    "sys.path.append(\"./src\")\n",
    "from misc import get_execution_role, wait_for_s3_object\n",
    "from docker_utils import build_and_push_docker_image\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "from IPython.display import Markdown\n",
    "from markdown_helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing basic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create a new bucket or use an existing bucket with allowed permissions\n",
    "useExistingBucket = True\n",
    "#if true , use exiting models else create a new model, make sure name is unique and add it to our \n",
    "#existing bucket only create a new folder\n",
    "FreireBucket = \"freirebros-deepracer\" #bucketname , this is global bucket (S3 Bucket)\n",
    "\n",
    "#the pretrained folder is incase yo have an old model already trained\n",
    "#if you have non then just call it \"\"\n",
    "#DO NOT PUT A  SLASH AT THE END IT MESSES EVERYTHING UP\n",
    "#pretrainedModelPrefix = \"AndreiModels/Model-Andrei-Trial-1-Custom-Architecture\" #this is the prefix name (a folder within sagemaker S3)\n",
    "#new model directory\n",
    "NewModelPrefix = \"AndreiModels/Model-Andrei-Trial-1-Custom-Architecture\"\n",
    "\n",
    "# Select the instance type\n",
    "instance_type = \"ml.c4.2xlarge\"\n",
    "#instance_type = \"ml.p2.xlarge\"\n",
    "#instance_type = \"ml.c5.4xlarge\"\n",
    "\n",
    "\n",
    "if not FreireBucket: \n",
    "    raise SystemExit(\"Please Enter a Bucket Name\")\n",
    "\n",
    "# Starting SageMaker session\n",
    "sage_session = sagemaker.session.Session(default_bucket = FreireBucket)\n",
    "\n",
    "# Create unique job name.\n",
    "job_name_prefix = 'deepracer-notebook'\n",
    "\n",
    "# Duration of job in seconds (1 hours)\n",
    "job_duration_in_seconds = 3600\n",
    "\n",
    "# AWS Region\n",
    "aws_region = sage_session.boto_region_name\n",
    "if aws_region not in [\"us-west-2\", \"us-east-1\", \"eu-west-1\"]:\n",
    "    raise Exception(\"This notebook uses RoboMaker which is available only in US East (N. Virginia),\"\n",
    "                    \"US West (Oregon) and EU (Ireland). Please switch to one of these regions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup S3 bucket\n",
    "Set up the linkage and authentication to the S3 bucket that we want to use for checkpoint and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using s3 bucket freirebros-deepracer\n",
      "Model checkpoints and other metadata will be stored at: \n",
      "s3://freirebros-deepracer/AndreiModels/Model-Andrei-Trial-1-Custom-Architecture\n"
     ]
    }
   ],
   "source": [
    "#Fetch S3 Bucket Resource\n",
    "if not NewModelPrefix:\n",
    "    raise systemExit(\"pleaser Enter a Prefix Name (Folder where the model is stored)\")\n",
    "# S3 bucket\n",
    "if not useExistingBucket:\n",
    "    s3_bucket = sage_session.default_bucket()\n",
    "else:\n",
    "    s3_bucket = FreireBucket\n",
    "# SDK appends the job name and output folder\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "\n",
    "#Ensure that the S3 prefix contains the keyword 'sagemaker'\n",
    "s3_prefix = NewModelPrefix\n",
    "\n",
    "# Get the AWS account id of this account\n",
    "sts = boto3.client(\"sts\")\n",
    "account_id = sts.get_caller_identity()['Account']\n",
    "\n",
    "print(\"Using s3 bucket {}\".format(s3_bucket))\n",
    "print(\"Model checkpoints and other metadata will be stored at: \\ns3://{}/{}\".format(s3_bucket, s3_prefix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an IAM role\n",
    "Either get the execution role when running from a SageMaker notebook `role = sagemaker.get_execution_role()` or, when running from local machine, use utils method `role = get_execution_role('role_name')` to create an execution role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Sagemaker IAM role arn: \n",
      "arn:aws:iam::204747776045:role/service-role/AmazonSageMaker-ExecutionRole-20210210T204480\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sagemaker_role = sagemaker.get_execution_role()\n",
    "except:\n",
    "    sagemaker_role = get_execution_role('sagemaker')\n",
    "\n",
    "print(\"Using Sagemaker IAM role arn: \\n{}\".format(sagemaker_role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Please note that this notebook cannot be run in `SageMaker local mode` as the simulator is based on AWS RoboMaker service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permission setup for invoking AWS RoboMaker from this notebook\n",
    "In order to enable this notebook to be able to execute AWS RoboMaker jobs, we need to add one trust relationship to the default execution role of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Go to IAM console to edit current SageMaker role: [AmazonSageMaker-ExecutionRole-20210210T204480](https://console.aws.amazon.com/iam/home#/roles/AmazonSageMaker-ExecutionRole-20210210T204480).\n",
       "2. Next, go to the `Trust relationships tab` and click on `Edit Trust Relationship.` \n",
       "3. Replace the JSON blob with the following:\n",
       "```json\n",
       "            {\n",
       "              \"Version\": \"2012-10-17\",\n",
       "              \"Statement\": [\n",
       "                {\n",
       "                  \"Effect\": \"Allow\",\n",
       "                  \"Principal\": {\n",
       "                    \"Service\": [\n",
       "                      \"sagemaker.amazonaws.com\",\n",
       "                      \"robomaker.amazonaws.com\"\n",
       "                    ]\n",
       "                  },\n",
       "                  \"Action\": \"sts:AssumeRole\"\n",
       "                }\n",
       "              ]\n",
       "            }```\n",
       "4. Once this is complete, click on Update Trust Policy and you are done."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(generate_help_for_robomaker_trust_relationship(sagemaker_role)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permission setup for Sagemaker to S3 bucket\n",
    "\n",
    "The sagemaker writes the Redis IP address, models to the S3 bucket. This requires PutObject permission on the bucket. Make sure the sagemaker role you are using as this permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Go to IAM console to edit current SageMaker role: [AmazonSageMaker-ExecutionRole-20210210T204480](https://console.aws.amazon.com/iam/home#/roles/AmazonSageMaker-ExecutionRole-20210210T204480).\n",
       "2. Next, go to the `Permissions tab` and click on `Attach Policy.` \n",
       "3. Search and select `AmazonKinesisVideoStreamsFullAccess` policy\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(generate_s3_write_permission_for_sagemaker_role(sagemaker_role)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permission setup for Sagemaker to create KinesisVideoStreams\n",
    "\n",
    "The sagemaker notebook has to create a kinesis video streamer. You can observer the car making epsiodes in the kinesis video streamer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Go to IAM console to edit current SageMaker role: [AmazonSageMaker-ExecutionRole-20210210T204480](https://console.aws.amazon.com/iam/home#/roles/AmazonSageMaker-ExecutionRole-20210210T204480).\n",
       "2. Next, go to the `Permissions tab` and click on `Attach Policy.` \n",
       "3. Search and select `AmazonS3FullAccess` policy\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(generate_kinesis_create_permission_for_sagemaker_role(sagemaker_role)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and push docker image\n",
    "\n",
    "The file ./Dockerfile contains all the packages that are installed into the docker. Instead of using the default sagemaker container. We will be using this docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying files from your notebook to existing sagemaker container\n",
      "docker images sagemaker-docker-cpu | sed -n 2,2p\n",
      "Creating sagemaker container\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Logged into ECR\n",
      "Building docker image sagemaker-docker-cpu from Dockerfile\n",
      "$ docker build -t sagemaker-docker-cpu -f Dockerfile . --build-arg CPU_OR_GPU=cpu --build-arg AWS_REGION=us-east-1\n",
      "Sending build context to Docker daemon   7.71GB\n",
      "Step 1/22 : ARG CPU_OR_GPU\n",
      "Step 2/22 : ARG AWS_REGION\n",
      "Step 3/22 : FROM 520713654638.dkr.ecr.$AWS_REGION.amazonaws.com/sagemaker-tensorflow-scriptmode:1.12.0-$CPU_OR_GPU-py3\n",
      " ---> ba542f0b9706\n",
      "Step 4/22 : COPY ./src/markov /opt/amazon/markov\n",
      " ---> Using cache\n",
      " ---> 615e39a602b9\n",
      "Step 5/22 : RUN apt-get update && apt-get install -y --no-install-recommends         build-essential         jq         libav-tools         libjpeg-dev         libxrender1         python3.6-dev         python3-opengl         wget         xvfb &&     apt-get clean &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 50a6f7d4c174\n",
      "Step 6/22 : RUN     cd /tmp &&     wget http://download.redis.io/redis-stable.tar.gz &&     tar xvzf redis-stable.tar.gz &&     cd redis-stable &&     make &&     make install\n",
      " ---> Using cache\n",
      " ---> 4f509783ff15\n",
      "Step 7/22 : RUN pip install     annoy==1.8.3     Pillow==4.3.0     matplotlib==2.0.2     numpy==1.14.5     pandas==0.22.0     pygame==1.9.3     PyOpenGL==3.1.0     scipy==1.2.1     scikit-image==0.15.0     futures==3.1.1     boto3==1.9.23     minio==4.0.5     kubernetes==7.0.0     opencv-python==4.1.1.26     bokeh==1.4.0     rl-coach-slim==1.0.0     retrying     eventlet     flask     gevent     gunicorn     pytest==5.4.1     pytest-cov==2.8.1\n",
      " ---> Running in aa3b730ddced\n",
      "Collecting annoy==1.8.3\n",
      "  Downloading https://files.pythonhosted.org/packages/3a/14/e733caa00f20544d4f3685434073a6911f4712e7316b140537a750cceb37/annoy-1.8.3.tar.gz (629kB)\n",
      "Collecting Pillow==4.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/5c/44a8f05da34cbb495e5330825c2204b9fa761357c87bc0bc1785b1d76e41/Pillow-4.3.0-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
      "Collecting matplotlib==2.0.2\n",
      "  Downloading https://files.pythonhosted.org/packages/60/d4/6b6d8a7a6bc69a1602ab372f6fc6e88ef88a8a96398a1a25edbac636295b/matplotlib-2.0.2-cp36-cp36m-manylinux1_x86_64.whl (14.6MB)\n",
      "Collecting numpy==1.14.5\n",
      "  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
      "Collecting pandas==0.22.0\n",
      "  Downloading https://files.pythonhosted.org/packages/da/c6/0936bc5814b429fddb5d6252566fe73a3e40372e6ceaf87de3dec1326f28/pandas-0.22.0-cp36-cp36m-manylinux1_x86_64.whl (26.2MB)\n",
      "Collecting pygame==1.9.3\n",
      "  Downloading https://files.pythonhosted.org/packages/e4/c7/f57009a23c8f0520031be7042aa78407d88843876b2a504d4990e753fb70/pygame-1.9.3-cp36-cp36m-manylinux1_x86_64.whl (9.4MB)\n",
      "Collecting PyOpenGL==3.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/9c/1d/4544708aaa89f26c97cc09450bb333a23724a320923e74d73e028b3560f9/PyOpenGL-3.1.0.tar.gz (1.2MB)\n",
      "Collecting scipy==1.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n",
      "\u001b[91mCould not install packages due to an EnvironmentError: [Errno 28] No space left on device: '/tmp/pip-install-q328tpqj/scipy'\n",
      "\n",
      "\u001b[0m\u001b[91mYou are using pip version 18.1, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mThe command '/bin/sh -c pip install     annoy==1.8.3     Pillow==4.3.0     matplotlib==2.0.2     numpy==1.14.5     pandas==0.22.0     pygame==1.9.3     PyOpenGL==3.1.0     scipy==1.2.1     scikit-image==0.15.0     futures==3.1.1     boto3==1.9.23     minio==4.0.5     kubernetes==7.0.0     opencv-python==4.1.1.26     bokeh==1.4.0     rl-coach-slim==1.0.0     retrying     eventlet     flask     gevent     gunicorn     pytest==5.4.1     pytest-cov==2.8.1' returned a non-zero code: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker', 'build', '-t', 'sagemaker-docker-cpu', '-f', 'Dockerfile', '.', '--build-arg', 'CPU_OR_GPU=cpu', '--build-arg', 'AWS_REGION=us-east-1'], Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/DeepRacer-Freire/copy_to_sagemaker_container.py\u001b[0m in \u001b[0;36mget_sagemaker_docker\u001b[0;34m(repository_short_name)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdocker_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SageMaker docker not found. Please check.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: SageMaker docker not found. Please check.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/SageMaker/DeepRacer-Freire/common/docker_utils.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(command, quiet)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/DeepRacer-Freire/common/docker_utils.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Process exited with code: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Process exited with code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/DeepRacer-Freire/common/docker_utils.py\u001b[0m in \u001b[0;36mbuild_and_push_docker_image\u001b[0;34m(repository_name, dockerfile, build_args)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mbase_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_base_image_in_dockerfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdockerfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0m_ecr_login_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0m_build_from_dockerfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepository_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdockerfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mecr_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepository_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mecr_tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/DeepRacer-Freire/common/docker_utils.py\u001b[0m in \u001b[0;36m_build_from_dockerfile\u001b[0;34m(repository_name, dockerfile, build_args)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building docker image %s from %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrepository_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdockerfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_cmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done building docker image %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepository_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/DeepRacer-Freire/common/docker_utils.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(command, quiet)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# which contains the exit code and append the command line to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to run: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker', 'build', '-t', 'sagemaker-docker-cpu', '-f', 'Dockerfile', '.', '--build-arg', 'CPU_OR_GPU=cpu', '--build-arg', 'AWS_REGION=us-east-1'], Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from copy_to_sagemaker_container import get_sagemaker_docker, copy_to_sagemaker_container, get_custom_image_name\n",
    "cpu_or_gpu = 'gpu' if instance_type.startswith('ml.p') else 'cpu'\n",
    "repository_short_name = \"sagemaker-docker-%s\" % cpu_or_gpu\n",
    "custom_image_name = get_custom_image_name(repository_short_name)\n",
    "try:\n",
    "    print(\"Copying files from your notebook to existing sagemaker container\")\n",
    "    sagemaker_docker_id = get_sagemaker_docker(repository_short_name)\n",
    "    copy_to_sagemaker_container(sagemaker_docker_id, repository_short_name)\n",
    "except Exception as e:\n",
    "    print(\"Creating sagemaker container\")\n",
    "    docker_build_args = {\n",
    "        'CPU_OR_GPU': cpu_or_gpu, \n",
    "        'AWS_REGION': boto3.Session().region_name,\n",
    "    }\n",
    "    custom_image_name = build_and_push_docker_image(repository_short_name, build_args=docker_build_args)\n",
    "    print(\"Using ECR image %s\" % custom_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the docker images\n",
    "Remove this only when you want to completely remove the docker or clean up the space of the sagemaker instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"docker rm\" requires at least 1 argument.\n",
      "See 'docker rm --help'.\n",
      "\n",
      "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n",
      "\n",
      "Remove one or more containers\n",
      "\"docker rmi\" requires at least 1 argument.\n",
      "See 'docker rmi --help'.\n",
      "\n",
      "Usage:  docker rmi [OPTIONS] IMAGE [IMAGE...]\n",
      "\n",
      "Remove one or more images\n"
     ]
    }
   ],
   "source": [
    "!docker rm -f $(docker ps -a -q);\n",
    "!docker rmi -f $(docker images -q);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure VPC\n",
    "\n",
    "Since SageMaker and RoboMaker have to communicate with each other over the network, both of these services need to run in VPC mode. This can be done by supplying subnets and security groups to the job launching scripts.  \n",
    "We will check if the deepracer-vpc stack is created and use it if present (This is present if the AWS Deepracer console is used atleast once to create a model). Else we will use the default VPC stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default VPC stacks\n",
      "Using VPC: vpc-6cebf416\n",
      "Using security group: ['sg-26446204']\n",
      "Using subnets: ['subnet-f638fb90', 'subnet-00ef2621', 'subnet-57bb7408', 'subnet-62283e5c', 'subnet-2293016f', 'subnet-f4d551fa']\n"
     ]
    }
   ],
   "source": [
    "ec2 = boto3.client('ec2')\n",
    "\n",
    "\n",
    "print(\"Using the default VPC stacks\")\n",
    "deepracer_vpc = [vpc['VpcId'] for vpc in ec2.describe_vpcs()['Vpcs'] if vpc[\"IsDefault\"] == True][0]\n",
    "\n",
    "deepracer_security_groups = [group[\"GroupId\"] for group in ec2.describe_security_groups()['SecurityGroups'] \\\n",
    "                             if 'VpcId' in group and group[\"GroupName\"] == \"default\" and group[\"VpcId\"] == deepracer_vpc]\n",
    "\n",
    "deepracer_subnets = [subnet[\"SubnetId\"] for subnet in ec2.describe_subnets()[\"Subnets\"] \\\n",
    "                     if subnet[\"VpcId\"] == deepracer_vpc and subnet['DefaultForAz']==True]\n",
    "\n",
    "print(\"Using VPC:\", deepracer_vpc)\n",
    "print(\"Using security group:\", deepracer_security_groups)\n",
    "print(\"Using subnets:\", deepracer_subnets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Route Table\n",
    "A SageMaker job running in VPC mode cannot access S3 resourcs. So, we need to create a VPC S3 endpoint to allow S3 access from SageMaker container. To learn more about the VPC mode, please visit [this link.](https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating \n",
      "Trying to attach S3 endpoints to the following route tables: ['rtb-d36ff5ad']\n",
      "S3 endpoint already exists.\n"
     ]
    }
   ],
   "source": [
    "#TODO: Explain to customer what CREATE_ROUTE_TABLE is doing\n",
    "CREATE_ROUTE_TABLE = True\n",
    "\n",
    "def create_vpc_endpoint_table():\n",
    "    print(\"Creating \")\n",
    "    try:\n",
    "        route_tables = [route_table[\"RouteTableId\"] for route_table in ec2.describe_route_tables()['RouteTables']\\\n",
    "                        if route_table['VpcId'] == deepracer_vpc]\n",
    "    except Exception as e:\n",
    "        if \"UnauthorizedOperation\" in str(e):\n",
    "            display(Markdown(generate_help_for_s3_endpoint_permissions(sagemaker_role)))\n",
    "        else:\n",
    "            display(Markdown(create_s3_endpoint_manually(aws_region, deepracer_vpc)))\n",
    "        raise e\n",
    "\n",
    "    print(\"Trying to attach S3 endpoints to the following route tables:\", route_tables)\n",
    "    \n",
    "    if not route_tables:\n",
    "        raise Exception((\"No route tables were found. Please follow the VPC S3 endpoint creation \"\n",
    "                         \"guide by clicking the above link.\"))\n",
    "    try:\n",
    "        ec2.create_vpc_endpoint(DryRun=False,\n",
    "                                VpcEndpointType=\"Gateway\",\n",
    "                                VpcId=deepracer_vpc,\n",
    "                                ServiceName=\"com.amazonaws.{}.s3\".format(aws_region),\n",
    "                                RouteTableIds=route_tables)\n",
    "        print(\"S3 endpoint created successfully!\")\n",
    "    except Exception as e:\n",
    "        if \"RouteAlreadyExists\" in str(e):\n",
    "            print(\"S3 endpoint already exists.\")\n",
    "        elif \"UnauthorizedOperation\" in str(e):\n",
    "            display(Markdown(generate_help_for_s3_endpoint_permissions(role)))\n",
    "            raise e\n",
    "        else:\n",
    "            display(Markdown(create_s3_endpoint_manually(aws_region, deepracer_vpc)))\n",
    "            raise e\n",
    "\n",
    "if CREATE_ROUTE_TABLE:\n",
    "    create_vpc_endpoint_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the environment\n",
    "\n",
    "The environment is defined in a Python file called “deepracer_racetrack_env.py” and the file can be found at `src/markov/environments/`. This file implements the gym interface for our Gazebo based RoboMakersimulator. This is a common environment file used by both SageMaker and RoboMaker. The environment variable - `NODE_TYPE` defines which node the code is running on. So, the expressions that have `rospy` dependencies are executed on RoboMaker only.  \n",
    "\n",
    "We can experiment with different reward functions by modifying `reward_function` in `src/markov/rewards/`. Action space and steering angles can be changed by modifying `src/markov/actions/`.json file\n",
    "\n",
    "### Configure the preset for RL algorithm\n",
    "\n",
    "The parameters that configure the RL training job are defined in `src/markov/presets/`. Using the preset file, you can define agent parameters to select the specific agent algorithm. We suggest using Clipped PPO for this example.  \n",
    "You can edit this file to modify algorithm parameters like learning_rate, neural network structure, batch_size, discount factor etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the pygmentize code lines to see the code\n",
    "\n",
    "# Reward function\n",
    "#!pygmentize src/markov/rewards/default.py\n",
    "\n",
    "# Action space\n",
    "#!pygmentize src/markov/actions/single_speed_stereo_shallow.json\n",
    "\n",
    "# Preset File\n",
    "#!pygmentize src/markov/presets/default.py\n",
    "#!pygmentize src/markov/presets/preset_attention_layer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy custom files to S3 bucket so that sagemaker & robomaker can pick it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://freirebros-deepracer/AndreiModels/Model-Andrei-Trial-1-Custom-Architecture\n",
      "delete: s3://freirebros-deepracer/AndreiModels/Model-Andrei-Trial-1-Custom-Architecture/model/model_metadata.json\n",
      "delete: s3://freirebros-deepracer/AndreiModels/Model-Andrei-Trial-1-Custom-Architecture/customer_reward_function.py\n",
      "upload: src/artifacts/rewards/andrei_reward_optimized_turns.py to s3://freirebros-deepracer/AndreiModels/Model-Andrei-Trial-1-Custom-Architecture/customer_reward_function.py\n",
      "upload: src/artifacts/actions/freire_continous_custom_architecture.json to s3://freirebros-deepracer/AndreiModels/Model-Andrei-Trial-1-Custom-Architecture/model/model_metadata.json\n"
     ]
    }
   ],
   "source": [
    "s3_location = \"s3://%s/%s\" % (s3_bucket, s3_prefix)\n",
    "print(s3_location)\n",
    "\n",
    "# Clean up the previously uploaded files\n",
    "!aws s3 rm --recursive {s3_location}\n",
    "\n",
    "!aws s3 cp ./src/artifacts/rewards/andrei_reward_optimized_turns.py {s3_location}/customer_reward_function.py\n",
    "\n",
    "!aws s3 cp ./src/artifacts/actions/freire_continous_custom_architecture.json {s3_location}/model/model_metadata.json\n",
    "\n",
    "#!aws s3 cp src/markov/presets/default.py {s3_location}/presets/preset.py\n",
    "#!aws s3 cp src/markov/presets/preset_attention_layer.py {s3_location}/presets/preset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the RL model using the Python SDK Script mode\n",
    "\n",
    "Next, we define the following algorithm metrics that we want to capture from cloudwatch logs to monitor the training progress. These are algorithm specific parameters and might change for different algorithm. We use [Clipped PPO](https://coach.nervanasys.com/algorithms/policy_optimization/cppo/index.html) for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    # Training> Name=main_level/agent, Worker=0, Episode=19, Total reward=-102.88, Steps=19019, Training iteration=1\n",
    "    {'Name': 'reward-training',\n",
    "     'Regex': '^Training>.*Total reward=(.*?),'},\n",
    "    \n",
    "    # Policy training> Surrogate loss=-0.32664725184440613, KL divergence=7.255815035023261e-06, Entropy=2.83156156539917, training epoch=0, learning_rate=0.00025\n",
    "    {'Name': 'ppo-surrogate-loss',\n",
    "     'Regex': '^Policy training>.*Surrogate loss=(.*?),'},\n",
    "     {'Name': 'ppo-entropy',\n",
    "     'Regex': '^Policy training>.*Entropy=(.*?),'},\n",
    "   \n",
    "    # Testing> Name=main_level/agent, Worker=0, Episode=19, Total reward=1359.12, Steps=20015, Training iteration=2\n",
    "    {'Name': 'reward-testing',\n",
    "     'Regex': '^Testing>.*Total reward=(.*?),'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the RLEstimator for training RL jobs.\n",
    "\n",
    "1. Specify the source directory which has the environment file, preset and training code.\n",
    "2. Specify the entry point as the training code\n",
    "3. Specify the choice of RL toolkit and framework. This automatically resolves to the ECR path for the RL Container.\n",
    "4. Define the training parameters such as the instance count, instance type, job name, s3_bucket and s3_prefix for storing model checkpoints and metadata. **Only 1 training instance is supported for now.**\n",
    "4. Set the RLCOACH_PRESET as \"deepracer\" for this example.\n",
    "5. Define the metrics definitions that you are interested in capturing in your logs. These can also be visualized in CloudWatch and SageMaker Notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job: deepracer-notebook-2021-04-07-03-47-10-918\n"
     ]
    }
   ],
   "source": [
    "estimator = RLEstimator(entry_point=\"base_training_worker.py\",\n",
    "                        source_dir='src',\n",
    "                        image_uri=custom_image_name,\n",
    "                        dependencies=[\"common/\"],\n",
    "                        role=sagemaker_role,\n",
    "                        instance_type=instance_type,\n",
    "                        instance_count=1,\n",
    "                        output_path=s3_output_path,\n",
    "                        base_job_name=job_name_prefix,\n",
    "                        metric_definitions=metric_definitions,\n",
    "                        max_run=job_duration_in_seconds,\n",
    "                        hyperparameters={\n",
    "                            \"s3_bucket\": s3_bucket,\n",
    "                            \"s3_prefix\": s3_prefix,\n",
    "                            \"aws_region\": aws_region,\n",
    "                            \"model_metadata_s3_key\": \"%s/model/model_metadata.json\" % s3_prefix,\n",
    "                            \"reward_function_s3_source\": \"%s/customer_reward_function.py\" % s3_prefix,\n",
    "                            \"batch_size\": \"64\",\n",
    "                            \"num_epochs\": \"10\",\n",
    "                            \"stack_size\": \"1\",\n",
    "                            \"lr\": \"0.0003\",\n",
    "                            \"exploration_type\": \"Categorical\",\n",
    "                            \"e_greedy_value\": \"1\",\n",
    "                            \"epsilon_steps\": \"10000\",\n",
    "                            \"beta_entropy\": \"0.01\",\n",
    "                            \"discount_factor\": \"0.999\",\n",
    "                            \"loss_type\": \"Huber\",\n",
    "                            \"num_episodes_between_training\": \"20\",\n",
    "                            \"max_sample_count\": \"0\",\n",
    "                            \"sampling_frequency\": \"1\"\n",
    "  #                          ,\"pretrained_s3_bucket\": FreireBucket\n",
    "  #                          ,\"pretrained_s3_prefix\": pretrainedModelPrefix\n",
    "                        },\n",
    "                        subnets=deepracer_subnets,\n",
    "                        security_group_ids=deepracer_security_groups,\n",
    "                    )\n",
    "\n",
    "estimator.fit(wait=False)\n",
    "job_name = estimator.latest_training_job.job_name\n",
    "print(\"Training job: %s\" % job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_arn = estimator.latest_training_job.describe()['TrainingJobArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Kinesis video stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"StreamARN\": \"arn:aws:kinesisvideo:us-east-1:204747776045:stream/dr-kvs-deepracer-notebook-2021-04-07-03-47-10-918/1617767240911\"\n",
      "}\n",
      "Created kinesis video stream dr-kvs-deepracer-notebook-2021-04-07-03-47-10-918\n"
     ]
    }
   ],
   "source": [
    "kvs_stream_name = \"dr-kvs-{}\".format(job_name)\n",
    "\n",
    "!aws --region {aws_region} kinesisvideo create-stream --stream-name {kvs_stream_name} --media-type video/h264 --data-retention-in-hours 24\n",
    "print (\"Created kinesis video stream {}\".format(kvs_stream_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Robomaker job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "robomaker = boto3.client(\"robomaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Simulation Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "robomaker_s3_key = 'robomaker/simulation_ws.tar.gz'\n",
    "robomaker_source = {'s3Bucket': s3_bucket,\n",
    "                    's3Key': robomaker_s3_key,\n",
    "                    'architecture': \"X86_64\"}\n",
    "simulation_software_suite={'name': 'Gazebo',\n",
    "                           'version': '7'}\n",
    "robot_software_suite={'name': 'ROS',\n",
    "                      'version': 'Kinetic'}\n",
    "rendering_engine={'name': 'OGRE',\n",
    "                  'version': '1.x'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the DeepRacer bundle provided by RoboMaker service and upload it in our S3 bucket to create a RoboMaker Simulation Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the simapp from build directory\n",
      "upload: build/output.tar.gz to s3://freirebros-deepracer/robomaker/simulation_ws.tar.gz\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./build/output.tar.gz'):\n",
    "    print(\"Using the latest simapp from public s3 bucket\")\n",
    "    # Download Robomaker simApp for the deepracer public s3 bucket\n",
    "    simulation_application_bundle_location = \"s3://deepracer-managed-resources-us-east-1/deepracer-simapp.tar.gz\"\n",
    "    !aws s3 cp {simulation_application_bundle_location} ./deepracer-simapp.tar.gz\n",
    "\n",
    "    # Remove if the Robomaker sim-app is present in s3 bucket\n",
    "    !aws s3 rm s3://{s3_bucket}/{robomaker_s3_key}\n",
    "\n",
    "    # Uploading the Robomaker SimApp to your S3 bucket\n",
    "    !aws s3 cp ./deepracer-simapp.tar.gz s3://{s3_bucket}/{robomaker_s3_key}\n",
    "\n",
    "    # Cleanup the locally downloaded version of SimApp\n",
    "    !rm deepracer-simapp.tar.gz\n",
    "else:\n",
    "    print(\"Using the simapp from build directory\")\n",
    "    !aws s3 cp ./build/output.tar.gz s3://{s3_bucket}/{robomaker_s3_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepracer-notebook-application210407-034755\n",
      "Created a new simulation app with ARN: arn:aws:robomaker:us-east-1:204747776045:simulation-application/deepracer-notebook-application210407-034755/1617767275551\n"
     ]
    }
   ],
   "source": [
    "app_name = \"deepracer-notebook-application\" + strftime(\"%y%m%d-%H%M%S\", gmtime())\n",
    "\n",
    "print(app_name)\n",
    "try:\n",
    "    response = robomaker.create_simulation_application(name=app_name,\n",
    "                                                       sources=[robomaker_source],\n",
    "                                                       simulationSoftwareSuite=simulation_software_suite,\n",
    "                                                       robotSoftwareSuite=robot_software_suite,\n",
    "                                                       renderingEngine=rendering_engine)\n",
    "    simulation_app_arn = response[\"arn\"]\n",
    "    print(\"Created a new simulation app with ARN:\", simulation_app_arn)\n",
    "except Exception as e:\n",
    "    if \"AccessDeniedException\" in str(e):\n",
    "        display(Markdown(generate_help_for_robomaker_all_permissions(role)))\n",
    "        raise e\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the Simulation job on RoboMaker\n",
    "\n",
    "We create [AWS RoboMaker](https://console.aws.amazon.com/robomaker/home#welcome) Simulation Jobs that simulates the environment and shares this data with SageMaker for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracks you can use, there may be more now need to recheck....\n",
    "# Albert.world                      Mexico_track.world                reinvent_wood.world\n",
    "# AmericasGeneratedInclStart.world  Monaco_building.world             Singapore_building.world\n",
    "# Aragon.world                      Monaco.world                      Singapore_f1.world\n",
    "# Austin.world                      New_York_Track.world              Singapore.world\n",
    "# AWS_track.world                   Oval_track.world                  Spain_track_f1.world\n",
    "# Belille.world                     reInvent2019_track.world          Spain_track.world\n",
    "# Bowtie_track.world                reInvent2019_wide_mirrored.world  Straight_track.world\n",
    "# Canada_Training.world             reInvent2019_wide.world           Tokyo_Training_track.world\n",
    "# China_track.world                 reinvent_base_jeremiah.world      Vegas_track.world\n",
    "# FS_June2020.world                 reinvent_base.world               Virtual_May19_Train_track.world\n",
    "# July_2020.world                   reinvent_carpet.world\n",
    "# LGSWide.world                     reinvent_concrete.world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_TYPE                                : TRAINING\n",
      "WORLD_NAME                              : Monaco_building\n",
      "SAGEMAKER_SHARED_S3_BUCKET              : freirebros-deepracer\n",
      "SAGEMAKER_SHARED_S3_PREFIX              : AndreiModels/Model-Andrei-Trial-1-Custom-Architecture\n",
      "TRAINING_JOB_ARN                        : arn:aws:sagemaker:us-east-1:204747776045:training-job/deepracer-notebook-2021-04-07-03-47-10-918\n",
      "METRICS_S3_BUCKET                       : freirebros-deepracer\n",
      "METRICS_S3_OBJECT_KEY                   : AndreiModels/Model-Andrei-Trial-1-Custom-Architecture/training_metrics.json\n",
      "SIMTRACE_S3_BUCKET                      : freirebros-deepracer\n",
      "SIMTRACE_S3_PREFIX                      : AndreiModels/Model-Andrei-Trial-1-Custom-Architecture/iteration-data/training\n",
      "AWS_REGION                              : us-east-1\n",
      "TARGET_REWARD_SCORE                     : None\n",
      "NUMBER_OF_EPISODES                      : 0\n",
      "ROBOMAKER_SIMULATION_JOB_ACCOUNT_ID     : 204747776045\n",
      "CHANGE_START_POSITION                   : true\n",
      "ALTERNATE_DRIVING_DIRECTION             : false\n",
      "REVERSE_DIR                             : false\n",
      "KINESIS_VIDEO_STREAM_NAME               : dr-kvs-deepracer-notebook-2021-04-07-03-47-10-918\n",
      "REWARD_FILE_S3_KEY                      : AndreiModels/Model-Andrei-Trial-1-Custom-Architecture/customer_reward_function.py\n",
      "MODEL_METADATA_FILE_S3_KEY              : AndreiModels/Model-Andrei-Trial-1-Custom-Architecture/model/model_metadata.json\n",
      "NUMBER_OF_RESETS                        : 0\n",
      "CAR_COLOR                               : Blue\n",
      "ENABLE_DOMAIN_RANDOMIZATION             : false\n",
      "NUM_WORKERS                             : 1\n",
      "NUMBER_OF_OBSTACLES                     : 0\n",
      "MIN_DISTANCE_BETWEEN_OBSTACLES          : 2.0\n",
      "RANDOMIZE_OBSTACLE_LOCATIONS            : false\n",
      "IS_OBSTACLE_BOT_CAR                     : false\n",
      "NUMBER_OF_BOT_CARS                      : 0\n",
      "IS_LANE_CHANGE                          : false\n",
      "LOWER_LANE_CHANGE_TIME                  : 3.0\n",
      "UPPER_LANE_CHANGE_TIME                  : 5.0\n",
      "LANE_CHANGE_DISTANCE                    : 1.0\n",
      "MIN_DISTANCE_BETWEEN_BOT_CARS           : 2.0\n",
      "RANDOMIZE_BOT_CAR_LOCATIONS             : true\n",
      "BOT_CAR_SPEED                           : 0.2\n",
      "MP4_S3_BUCKET                           : freirebros-deepracer\n",
      "MP4_S3_OBJECT_PREFIX                    : AndreiModels/Model-Andrei-Trial-1-Custom-Architecture/iteration-data/training\n",
      "RACE_TYPE                               : TIME_TRIAL\n",
      "VIDEO_JOB_TYPE                          : RACING\n",
      "DISPLAY_NAME                            : LongLongRacerNameBlaBlaBla\n",
      "RACER_NAME                              : racer-alias\n",
      "MODEL_NAME                              : bla-bla-model-user-created-in-customer\n",
      "LEADERBOARD_TYPE                        : LEAGUE\n",
      "LEADERBOARD_NAME                        : 2020 MARCH QUALIFIER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:7: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1.8 KiB/1.8 KiB (22.3 KiB/s) with 1 file(s) remaining\r",
      "upload: ./training_params.yaml to s3://freirebros-deepracer/AndreiModels/Model-Andrei-Trial-1-Custom-Architecture/training_params.yaml\r\n"
     ]
    }
   ],
   "source": [
    "s3_yaml_name=\"training_params.yaml\"\n",
    "world_name = \"Monaco_building\"\n",
    "# Change this for multiple rollouts. This will invoke the specified number of robomaker jobs to collect experience\n",
    "num_simulation_workers = 1\n",
    "\n",
    "with open(\"./src/artifacts/yaml/training_yaml_template.yaml\", \"r\") as filepointer:\n",
    "    yaml_config = yaml.load(filepointer)\n",
    "\n",
    "yaml_config['WORLD_NAME']                  = world_name\n",
    "yaml_config['SAGEMAKER_SHARED_S3_BUCKET']  = s3_bucket\n",
    "yaml_config['SAGEMAKER_SHARED_S3_PREFIX']  = s3_prefix\n",
    "yaml_config['TRAINING_JOB_ARN']            = training_job_arn\n",
    "yaml_config['METRICS_S3_BUCKET']           = s3_bucket\n",
    "yaml_config['METRICS_S3_OBJECT_KEY']       = \"{}/training_metrics.json\".format(s3_prefix)\n",
    "yaml_config['SIMTRACE_S3_BUCKET']          = s3_bucket\n",
    "yaml_config['SIMTRACE_S3_PREFIX']          = \"{}/iteration-data/training\".format(s3_prefix)\n",
    "yaml_config['AWS_REGION']                  = aws_region\n",
    "yaml_config['ROBOMAKER_SIMULATION_JOB_ACCOUNT_ID'] = account_id\n",
    "yaml_config['KINESIS_VIDEO_STREAM_NAME']   = kvs_stream_name\n",
    "yaml_config['REWARD_FILE_S3_KEY']          = \"{}/customer_reward_function.py\".format(s3_prefix)\n",
    "yaml_config['MODEL_METADATA_FILE_S3_KEY']  = \"{}/model/model_metadata.json\".format(s3_prefix)\n",
    "yaml_config['NUM_WORKERS']                 = num_simulation_workers\n",
    "yaml_config['MP4_S3_BUCKET']               = s3_bucket\n",
    "yaml_config['MP4_S3_OBJECT_PREFIX']        = \"{}/iteration-data/training\".format(s3_prefix)\n",
    "\n",
    "# Race-type supported for training are TIME_TRIAL, OBJECT_AVOIDANCE, HEAD_TO_BOT\n",
    "# If you need to modify more attributes look at the template yaml file\n",
    "race_type = \"TIME_TRIAL\"\n",
    "\n",
    "if race_type == \"OBJECT_AVOIDANCE\":\n",
    "    yaml_config['NUMBER_OF_OBSTACLES']     = \"6\"\n",
    "    yaml_config['RACE_TYPE']               = \"OBJECT_AVOIDANCE\"\n",
    "\n",
    "elif race_type == \"HEAD_TO_BOT\":\n",
    "    yaml_config['NUMBER_OF_BOT_CARS']      = \"6\"\n",
    "    yaml_config['RACE_TYPE']               = \"HEAD_TO_BOT\"\n",
    "\n",
    "# Printing the modified yaml parameter\n",
    "for key, value in yaml_config.items():\n",
    "    print(\"{}: {}\".format(key.ljust(40, ' '), value))\n",
    "\n",
    "# Uploading the modified yaml parameter\n",
    "with open(\"./training_params.yaml\", \"w\") as filepointer:\n",
    "    yaml.dump(yaml_config, filepointer)\n",
    "\n",
    "!aws s3 cp ./training_params.yaml {s3_location}/training_params.yaml\n",
    "!rm training_params.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the following jobs:\n",
      "Job ARN arn:aws:robomaker:us-east-1:204747776045:simulation-job/sim-ghjw07f9f3hw\n"
     ]
    }
   ],
   "source": [
    "vpcConfig = {\"subnets\": deepracer_subnets,\n",
    "             \"securityGroups\": deepracer_security_groups,\n",
    "             \"assignPublicIp\": True}\n",
    "\n",
    "responses = []\n",
    "for job_no in range(num_simulation_workers):\n",
    "    client_request_token = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "    envriron_vars = {\n",
    "        \"S3_YAML_NAME\": s3_yaml_name,\n",
    "        \"SAGEMAKER_SHARED_S3_PREFIX\": s3_prefix,\n",
    "        \"SAGEMAKER_SHARED_S3_BUCKET\": s3_bucket,\n",
    "        \"WORLD_NAME\": world_name,\n",
    "        \"KINESIS_VIDEO_STREAM_NAME\": kvs_stream_name,\n",
    "        \"APP_REGION\": aws_region,\n",
    "        \"MODEL_METADATA_FILE_S3_KEY\": \"%s/model/model_metadata.json\" % s3_prefix,\n",
    "        \"ROLLOUT_IDX\": str(job_no)\n",
    "    }\n",
    "\n",
    "    simulation_application = {\"application\":simulation_app_arn,\n",
    "                              \"launchConfig\": {\"packageName\": \"deepracer_simulation_environment\",\n",
    "                                               \"launchFile\": \"distributed_training.launch\",\n",
    "                                               \"environmentVariables\": envriron_vars}\n",
    "                             }\n",
    "    response =  robomaker.create_simulation_job(iamRole=sagemaker_role,\n",
    "                                            clientRequestToken=client_request_token,\n",
    "                                            maxJobDurationInSeconds=job_duration_in_seconds,\n",
    "                                            failureBehavior=\"Fail\",\n",
    "                                            simulationApplications=[simulation_application],\n",
    "                                            vpcConfig=vpcConfig\n",
    "                                            )\n",
    "    responses.append(response)\n",
    "    time.sleep(5)\n",
    "    \n",
    "\n",
    "print(\"Created the following jobs:\")\n",
    "job_arns = [response[\"arn\"] for response in responses]\n",
    "for job_arn in job_arns:\n",
    "    print(\"Job ARN\", job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the simulations in RoboMaker\n",
    "You can visit the RoboMaker console to visualize the simulations or run the following cell to generate the hyperlinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Click on the following links for visualization of simulation jobs on RoboMaker Console\n",
       "- [Simulation 1](https://us-east-1.console.aws.amazon.com/robomaker/home?region=us-east-1#simulationJobs/sim-ghjw07f9f3hw)  \n",
       "\n",
       "You can click on Gazebo after you open the above link to start the simulator."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(generate_robomaker_links(job_arns, aws_region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating temporary folder top plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create local folder /tmp/deepracer-notebook-2021-04-07-03-47-10-918\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = \"/tmp/{}\".format(job_name)\n",
    "os.system(\"mkdir {}\".format(tmp_dir))\n",
    "print(\"Create local folder {}\".format(tmp_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot metrics for training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for s3://freirebros-deepracer/AndreiModels/Model-Andrei-Trial-1-Custom-Architecture/training_metrics.json......."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-5172fb610fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtraining_metrics_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"training_metrics.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtraining_metrics_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_metrics_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mwait_for_s3_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_bucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_metrics_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_metrics_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/DeepRacer-Freire/common/misc.py\u001b[0m in \u001b[0;36mwait_for_s3_object\u001b[0;34m(s3_bucket, key, local_dir, local_prefix, aws_account, aws_region, timeout, limit, fetch_only, training_job_name)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m80\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "training_metrics_file = \"training_metrics.json\"\n",
    "training_metrics_path = \"{}/{}\".format(s3_prefix, training_metrics_file)\n",
    "wait_for_s3_object(s3_bucket, training_metrics_path, tmp_dir)\n",
    "\n",
    "json_file = \"{}/{}\".format(tmp_dir, training_metrics_file)\n",
    "with open(json_file) as fp:  \n",
    "    data = json.load(fp)\n",
    "\n",
    "df = pd.DataFrame(data['metrics'])\n",
    "x_axis = 'episode'\n",
    "y_axis = 'reward_score'\n",
    "\n",
    "plt = df.plot(x=x_axis,y=y_axis, figsize=(12,5), legend=True, style='b-')\n",
    "plt.set_ylabel(y_axis);\n",
    "plt.set_xlabel(x_axis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up RoboMaker and SageMaker training job\n",
    "\n",
    "Execute the cells below if you want to kill RoboMaker and SageMaker job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancelling robomaker job\n",
    "for job_arn in job_arns:\n",
    "    robomaker.cancel_simulation_job(job=job_arn)\n",
    "\n",
    "# Stopping sagemaker training job\n",
    "sage_session.sagemaker_client.stop_training_job(TrainingJobName=estimator._current_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (Time trail, Object avoidance, Head to bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_TYPE                                : EVALUATION\n",
      "WORLD_NAME                              : Monaco_building\n",
      "MODEL_S3_BUCKET                         : freirebros-deepracer\n",
      "MODEL_S3_PREFIX                         : AndreiModels/Model-Andrei-Trial-2-Continuous\n",
      "AWS_REGION                              : us-east-1\n",
      "METRICS_S3_BUCKET                       : freirebros-deepracer\n",
      "METRICS_S3_OBJECT_KEY                   : AndreiModels/Model-Andrei-Trial-2-Continuous/evaluation_metrics.json\n",
      "SIMTRACE_S3_BUCKET                      : freirebros-deepracer\n",
      "SIMTRACE_S3_PREFIX                      : AndreiModels/Model-Andrei-Trial-2-Continuous/iteration-data/evaluation\n",
      "NUMBER_OF_TRIALS                        : 5\n",
      "ROBOMAKER_SIMULATION_JOB_ACCOUNT_ID     : 204747776045\n",
      "CAR_COLOR                               : Grey\n",
      "NUMBER_OF_RESETS                        : 10000\n",
      "PENALTY_SECONDS                         : 2.0\n",
      "IS_CONTINUOUS                           : false\n",
      "OFF_TRACK_PENALTY                       : 0.0\n",
      "COLLISION_PENALTY                       : 0.0\n",
      "ENABLE_DOMAIN_RANDOMIZATION             : false\n",
      "REVERSE_DIR                             : false\n",
      "NUMBER_OF_OBSTACLES                     : 0\n",
      "MIN_DISTANCE_BETWEEN_OBSTACLES          : 2.0\n",
      "RANDOMIZE_OBSTACLE_LOCATIONS            : false\n",
      "IS_OBSTACLE_BOT_CAR                     : false\n",
      "NUMBER_OF_BOT_CARS                      : 0\n",
      "IS_LANE_CHANGE                          : false\n",
      "LOWER_LANE_CHANGE_TIME                  : 3.0\n",
      "UPPER_LANE_CHANGE_TIME                  : 5.0\n",
      "LANE_CHANGE_DISTANCE                    : 1.0\n",
      "MIN_DISTANCE_BETWEEN_BOT_CARS           : 2.0\n",
      "RANDOMIZE_BOT_CAR_LOCATIONS             : true\n",
      "BOT_CAR_SPEED                           : 0.2\n",
      "MP4_S3_BUCKET                           : freirebros-deepracer\n",
      "MP4_S3_OBJECT_PREFIX                    : AndreiModels/Model-Andrei-Trial-2-Continuous/iteration-data/evaluation\n",
      "RACE_TYPE                               : TIME_TRIAL\n",
      "VIDEO_JOB_TYPE                          : RACING\n",
      "DISPLAY_NAME                            : LongLongRacerNameBlaBlaBla\n",
      "RACER_NAME                              : racer-alias\n",
      "MODEL_NAME                              : bla-bla-model-user-created-in-customer\n",
      "LEADERBOARD_TYPE                        : LEAGUE\n",
      "LEADERBOARD_NAME                        : 2020 MARCH QUALIFIER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1.4 KiB/1.4 KiB (12.5 KiB/s) with 1 file(s) remaining\r",
      "upload: ./evaluation_params.yaml to s3://freirebros-deepracer/AndreiModels/Model-Andrei-Trial-2-Continuous/evaluation_params.yaml\r\n"
     ]
    }
   ],
   "source": [
    "s3_yaml_name=\"evaluation_params.yaml\"\n",
    "world_name = \"Monaco_building\"\n",
    "\n",
    "with open(\"./src/artifacts/yaml/evaluation_yaml_template.yaml\", \"r\") as filepointer:\n",
    "    yaml_config = yaml.load(filepointer)\n",
    "\n",
    "yaml_config['WORLD_NAME']                  = world_name\n",
    "yaml_config['MODEL_S3_BUCKET']             = s3_bucket\n",
    "yaml_config['MODEL_S3_PREFIX']             = s3_prefix\n",
    "yaml_config['AWS_REGION']                  = aws_region\n",
    "yaml_config['METRICS_S3_BUCKET']           = s3_bucket\n",
    "yaml_config['METRICS_S3_OBJECT_KEY']       = \"{}/evaluation_metrics.json\".format(s3_prefix)\n",
    "yaml_config['SIMTRACE_S3_BUCKET']          = s3_bucket\n",
    "yaml_config['SIMTRACE_S3_PREFIX']          = \"{}/iteration-data/evaluation\".format(s3_prefix)\n",
    "yaml_config['ROBOMAKER_SIMULATION_JOB_ACCOUNT_ID'] = account_id\n",
    "yaml_config['NUMBER_OF_TRIALS']            = \"5\"\n",
    "yaml_config['MP4_S3_BUCKET']               = s3_bucket\n",
    "yaml_config['MP4_S3_OBJECT_PREFIX']        = \"{}/iteration-data/evaluation\".format(s3_prefix)\n",
    "\n",
    "# Race-type supported for training are TIME_TRIAL, OBJECT_AVOIDANCE, HEAD_TO_BOT\n",
    "# If you need to modify more attributes look at the template yaml file\n",
    "race_type = \"TIME_TRIAL\"\n",
    "\n",
    "if race_type == \"OBJECT_AVOIDANCE\":\n",
    "    yaml_config['NUMBER_OF_OBSTACLES']     = \"6\"\n",
    "    yaml_config['RACE_TYPE']               = \"OBJECT_AVOIDANCE\"\n",
    "\n",
    "elif race_type == \"HEAD_TO_BOT\":\n",
    "    yaml_config['NUMBER_OF_BOT_CARS']      = \"6\"\n",
    "    yaml_config['RACE_TYPE']               = \"HEAD_TO_BOT\"\n",
    "\n",
    "# Printing the modified yaml parameter\n",
    "for key, value in yaml_config.items():\n",
    "    print(\"{}: {}\".format(key.ljust(40, ' '), value))\n",
    "\n",
    "# Uploading the modified yaml parameter\n",
    "with open(\"./evaluation_params.yaml\", \"w\") as filepointer:\n",
    "    yaml.dump(yaml_config, filepointer)\n",
    "\n",
    "!aws s3 cp ./evaluation_params.yaml {s3_location}/evaluation_params.yaml\n",
    "!rm evaluation_params.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the following jobs:\n",
      "Job ARN arn:aws:robomaker:us-east-1:204747776045:simulation-job/sim-mhmcdqy9p03m\n"
     ]
    }
   ],
   "source": [
    "num_simulation_workers = 1\n",
    "\n",
    "envriron_vars = {\n",
    "    \"S3_YAML_NAME\": s3_yaml_name,\n",
    "    \"MODEL_S3_PREFIX\": s3_prefix,\n",
    "    \"MODEL_S3_BUCKET\": s3_bucket,\n",
    "    \"WORLD_NAME\": world_name,\n",
    "    \"KINESIS_VIDEO_STREAM_NAME\": kvs_stream_name,\n",
    "    \"APP_REGION\": aws_region,\n",
    "    \"MODEL_METADATA_FILE_S3_KEY\": \"%s/model/model_metadata.json\" % s3_prefix\n",
    "}\n",
    "\n",
    "simulation_application = {\n",
    "    \"application\":simulation_app_arn,\n",
    "    \"launchConfig\": {\n",
    "         \"packageName\": \"deepracer_simulation_environment\",\n",
    "         \"launchFile\": \"evaluation.launch\",\n",
    "         \"environmentVariables\": envriron_vars\n",
    "    }\n",
    "}\n",
    "                            \n",
    "vpcConfig = {\"subnets\": deepracer_subnets,\n",
    "             \"securityGroups\": deepracer_security_groups,\n",
    "             \"assignPublicIp\": True}\n",
    "\n",
    "responses = []\n",
    "for job_no in range(num_simulation_workers):\n",
    "    response =  robomaker.create_simulation_job(clientRequestToken=strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()),\n",
    "                                                outputLocation={ \n",
    "                                                  \"s3Bucket\": s3_bucket,\n",
    "                                                  \"s3Prefix\": s3_prefix\n",
    "                                                },\n",
    "                                                maxJobDurationInSeconds=job_duration_in_seconds,\n",
    "                                                iamRole=sagemaker_role,\n",
    "                                                failureBehavior=\"Fail\",\n",
    "                                                simulationApplications=[simulation_application],\n",
    "                                                vpcConfig=vpcConfig)\n",
    "    responses.append(response)\n",
    "\n",
    "print(\"Created the following jobs:\")\n",
    "job_arns = [response[\"arn\"] for response in responses]\n",
    "for job_arn in job_arns:\n",
    "    print(\"Job ARN\", job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the simulations in RoboMaker\n",
    "You can visit the RoboMaker console to visualize the simulations or run the following cell to generate the hyperlinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Click on the following links for visualization of simulation jobs on RoboMaker Console\n",
       "- [Simulation 1](https://us-east-1.console.aws.amazon.com/robomaker/home?region=us-east-1#simulationJobs/sim-mhmcdqy9p03m)  \n",
       "\n",
       "You can click on Gazebo after you open the above link to start the simulator."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(generate_robomaker_links(job_arns, aws_region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating temporary folder top plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for s3://freirebros-deepracer/AndreiModels/Model-Andrei-Trial-2-Continuous/evaluation_metrics.json...\n",
      "Downloading AndreiModels/Model-Andrei-Trial-2-Continuous/evaluation_metrics.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>completion_percentage</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>47.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>50.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>49.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>49.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>50.272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial  completion_percentage  elapsed_time\n",
       "0      1                    100        47.551\n",
       "1      2                    100        50.445\n",
       "2      3                    100        49.870\n",
       "3      4                    100        49.226\n",
       "4      5                    100        50.272"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_metrics_file = \"evaluation_metrics.json\"\n",
    "evaluation_metrics_path = \"{}/{}\".format(s3_prefix, evaluation_metrics_file)\n",
    "wait_for_s3_object(s3_bucket, evaluation_metrics_path, tmp_dir)\n",
    "\n",
    "json_file = \"{}/{}\".format(tmp_dir, evaluation_metrics_file)\n",
    "with open(json_file) as fp:  \n",
    "    data = json.load(fp)\n",
    "\n",
    "df = pd.DataFrame(data['metrics'])\n",
    "# Converting milliseconds to seconds\n",
    "df['elapsed_time'] = df['elapsed_time_in_milliseconds']/1000\n",
    "df = df[['trial', 'completion_percentage', 'elapsed_time']]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up Simulation Application Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'c5cfe3ac-2476-42c7-9e31-293773bff788',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Wed, 31 Mar 2021 01:59:45 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'c5cfe3ac-2476-42c7-9e31-293773bff788',\n",
       "   'x-amz-apigw-id': 'dB6eyGOTIAMF08A=',\n",
       "   'x-amzn-trace-id': 'Root=1-6063d791-7fc99de1263fa8bd45a45b5c'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robomaker.delete_simulation_application(application=simulation_app_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean your S3 bucket (Uncomment the awscli commands if you want to do it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you only want to clean the s3 bucket\n",
    "sagemaker_s3_folder = \"s3://{}/{}\".format(s3_bucket, s3_prefix)\n",
    "!aws s3 rm --recursive {sagemaker_s3_folder}\n",
    "\n",
    "robomaker_s3_folder = \"s3://{}/{}\".format(s3_bucket, job_name)\n",
    "!aws s3 rm --recursive {robomaker_s3_folder}\n",
    "\n",
    "robomaker_sim_app = \"s3://{}/{}\".format(s3_bucket, 'robomaker')\n",
    "!aws s3 rm --recursive {robomaker_sim_app}\n",
    "\n",
    "model_output = \"s3://{}/{}\".format(s3_bucket, s3_bucket)\n",
    "!aws s3 rm --recursive {model_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head-to-head Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket\n",
    "s3_bucket_2 = sage_session.default_bucket()\n",
    "\n",
    "# Ensure that the S3 prefix contains the keyword 'sagemaker'\n",
    "# e.g.\"deepracer-notebook-sagemaker-200422-231836\"\n",
    "# Please provide the second agents s3_prefix\n",
    "s3_prefix_2 = \"[FILL OUT PREFIX]\"\n",
    "if not s3_prefix_2:\n",
    "    raise Exception(\"Please provide the second agents s3_prefix and s3_bucket. The prefix would have sagemaker in between\")\n",
    "\n",
    "print(\"Using s3 bucket {}\".format(s3_bucket_2))\n",
    "print(\"Model checkpoints and other metadata will be stored at: \\ns3://{}/{}\".format(s3_bucket_2, s3_prefix_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_yaml_name=\"evaluation_params.yaml\"\n",
    "world_name = \"reInvent2019_track\"\n",
    "\n",
    "with open(\"./src/artifacts/yaml/head2head_yaml_template.yaml\", \"r\") as filepointer:\n",
    "    yaml_config = yaml.load(filepointer)\n",
    "\n",
    "yaml_config['WORLD_NAME']                  = world_name\n",
    "yaml_config['MODEL_S3_BUCKET']             = [s3_bucket,\n",
    "                                              s3_bucket_2]\n",
    "yaml_config['MODEL_S3_PREFIX']             = [s3_prefix,\n",
    "                                              s3_prefix_2]\n",
    "yaml_config['MODEL_METADATA_FILE_S3_KEY']  =[\"{}/model/model_metadata.json\".format(s3_prefix),\n",
    "                                             \"{}/model/model_metadata.json\".format(s3_prefix_2)]\n",
    "yaml_config['AWS_REGION']                  = aws_region\n",
    "yaml_config['METRICS_S3_BUCKET']           = [s3_bucket,\n",
    "                                              s3_bucket_2]\n",
    "yaml_config['METRICS_S3_OBJECT_KEY']       = [\"{}/evaluation_metrics.json\".format(s3_prefix),\n",
    "                                              \"{}/evaluation_metrics.json\".format(s3_prefix_2)]\n",
    "yaml_config['SIMTRACE_S3_BUCKET']          = [s3_bucket,\n",
    "                                              s3_bucket_2]\n",
    "yaml_config['SIMTRACE_S3_PREFIX']          = [\"{}/iteration-data/evaluation\".format(s3_prefix),\n",
    "                                              \"{}/iteration-data/evaluation\".format(s3_prefix_2)]\n",
    "yaml_config['ROBOMAKER_SIMULATION_JOB_ACCOUNT_ID'] = account_id\n",
    "yaml_config['NUMBER_OF_TRIALS']            = \"5\"\n",
    "yaml_config['MP4_S3_BUCKET']               = [s3_bucket,\n",
    "                                              s3_bucket_2]\n",
    "yaml_config['MP4_S3_OBJECT_PREFIX']        = [\"{}/iteration-data/evaluation\".format(s3_prefix),\n",
    "                                              \"{}/iteration-data/evaluation\".format(s3_prefix_2)]\n",
    "\n",
    "# Race-type supported for training are TIME_TRIAL, OBJECT_AVOIDANCE, HEAD_TO_BOT\n",
    "# If you need to modify more attributes look at the template yaml file\n",
    "race_type = \"TIME_TRIAL\"\n",
    "\n",
    "if race_type == \"OBJECT_AVOIDANCE\":\n",
    "    yaml_config['NUMBER_OF_OBSTACLES']     = \"6\"\n",
    "    yaml_config['RACE_TYPE']               = \"OBJECT_AVOIDANCE\"\n",
    "\n",
    "elif race_type == \"HEAD_TO_BOT\":\n",
    "    yaml_config['NUMBER_OF_BOT_CARS']      = \"6\"\n",
    "    yaml_config['RACE_TYPE']               = \"HEAD_TO_BOT\"\n",
    "\n",
    "# Printing the modified yaml parameter\n",
    "for key, value in yaml_config.items():\n",
    "    print(\"{}: {}\".format(key.ljust(40, ' '), value))\n",
    "\n",
    "# Uploading the modified yaml parameter\n",
    "with open(\"./evaluation_params.yaml\", \"w\") as filepointer:\n",
    "    yaml.dump(yaml_config, filepointer)\n",
    "\n",
    "!aws s3 cp ./evaluation_params.yaml {s3_location}/evaluation_params.yaml\n",
    "!rm evaluation_params.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulation_workers = 1\n",
    "\n",
    "envriron_vars = {\n",
    "    \"S3_YAML_NAME\": s3_yaml_name,\n",
    "    \"MODEL_S3_PREFIX\": s3_prefix,\n",
    "    \"MODEL_S3_BUCKET\": s3_bucket,\n",
    "    \"WORLD_NAME\": world_name,\n",
    "    \"KINESIS_VIDEO_STREAM_NAME\": kvs_stream_name,\n",
    "    \"APP_REGION\": aws_region,\n",
    "    \"MODEL_METADATA_FILE_S3_KEY\": \"%s/model/model_metadata.json\" % s3_prefix\n",
    "}\n",
    "\n",
    "simulation_application = {\n",
    "    \"application\":simulation_app_arn,\n",
    "    \"launchConfig\": {\n",
    "         \"packageName\": \"deepracer_simulation_environment\",\n",
    "         \"launchFile\": \"evaluation.launch\",\n",
    "         \"environmentVariables\": envriron_vars\n",
    "    }\n",
    "}\n",
    "                            \n",
    "vpcConfig = {\"subnets\": deepracer_subnets,\n",
    "             \"securityGroups\": deepracer_security_groups,\n",
    "             \"assignPublicIp\": True}\n",
    "\n",
    "responses = []\n",
    "for job_no in range(num_simulation_workers):\n",
    "    response =  robomaker.create_simulation_job(clientRequestToken=strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()),\n",
    "                                                outputLocation={ \n",
    "                                                  \"s3Bucket\": s3_bucket,\n",
    "                                                  \"s3Prefix\": s3_prefix\n",
    "                                                },\n",
    "                                                maxJobDurationInSeconds=job_duration_in_seconds,\n",
    "                                                iamRole=sagemaker_role,\n",
    "                                                failureBehavior=\"Fail\",\n",
    "                                                simulationApplications=[simulation_application],\n",
    "                                                vpcConfig=vpcConfig)\n",
    "    responses.append(response)\n",
    "\n",
    "print(\"Created the following jobs:\")\n",
    "job_arns = [response[\"arn\"] for response in responses]\n",
    "for job_arn in job_arns:\n",
    "    print(\"Job ARN\", job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the simulations in RoboMaker\n",
    "You can visit the RoboMaker console to visualize the simulations or run the following cell to generate the hyperlinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(generate_robomaker_links(job_arns, aws_region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating temporary folder top plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics_file = \"evaluation_metrics.json\"\n",
    "evaluation_metrics_path = \"{}/{}\".format(s3_prefix, evaluation_metrics_file)\n",
    "wait_for_s3_object(s3_bucket, evaluation_metrics_path, tmp_dir)\n",
    "\n",
    "json_file = \"{}/{}\".format(tmp_dir, evaluation_metrics_file)\n",
    "with open(json_file) as fp:  \n",
    "    data = json.load(fp)\n",
    "\n",
    "df_1 = pd.DataFrame(data['metrics'])\n",
    "# Converting milliseconds to seconds\n",
    "df_1['elapsed_time'] = df_1['elapsed_time_in_milliseconds']/1000\n",
    "df_1 = df_1[['trial', 'completion_percentage', 'elapsed_time']]\n",
    "\n",
    "display(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics_file = \"evaluation_metrics.json\"\n",
    "evaluation_metrics_path = \"{}/{}\".format(s3_prefix_2, evaluation_metrics_file)\n",
    "wait_for_s3_object(s3_bucket_2, evaluation_metrics_path, tmp_dir)\n",
    "\n",
    "json_file = \"{}/{}\".format(tmp_dir, evaluation_metrics_file)\n",
    "with open(json_file) as fp:  \n",
    "    data = json.load(fp)\n",
    "\n",
    "df_2 = pd.DataFrame(data['metrics'])\n",
    "# Converting milliseconds to seconds\n",
    "df_2['elapsed_time'] = df_2['elapsed_time_in_milliseconds']/1000\n",
    "df_2 = df_2[['trial', 'completion_percentage', 'elapsed_time']]\n",
    "\n",
    "display(df_2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
